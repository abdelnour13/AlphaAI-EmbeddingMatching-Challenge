{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = os.path.join(\"..\",\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA,\"train_data.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA,\"test_data.csv\"))\n",
    "train_embeddings = pd.read_csv(os.path.join(DATA, \"train_embeddings.csv\"))\n",
    "test_embeddings = pd.read_csv(os.path.join(DATA, \"test_embeddings.csv\"))\n",
    "train_labels = pd.read_csv(os.path.join(DATA, \"train_labels.csv\"))\n",
    "test_labels = pd.read_csv(os.path.join(DATA, \"test_labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 785) (10000, 785)\n",
      "(128, 128) (10000, 128)\n",
      "(128, 1) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "print(train_embeddings.shape, test_embeddings.shape)\n",
    "print(train_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 784]) torch.Size([10000, 784])\n"
     ]
    }
   ],
   "source": [
    "dtrain = torch.tensor(train_df.drop(columns=['label']).to_numpy(), dtype=torch.float32).div(255.0)\n",
    "dtest = torch.tensor(test_df.drop(columns=['label']).to_numpy(), dtype=torch.float32).div(255.0)\n",
    "print(dtrain.shape, dtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128]) torch.Size([10000, 128])\n"
     ]
    }
   ],
   "source": [
    "train_embeddings_tensor = torch.tensor(train_embeddings.to_numpy(), dtype=torch.float32)\n",
    "test_embeddings_tensor = torch.tensor(test_embeddings.to_numpy(), dtype=torch.float32)\n",
    "print(train_embeddings_tensor.shape, test_embeddings_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exploit the fact that network used to generate the embeddings preserved the cosine similarity between the different samples.\n",
    "\n",
    "$$\n",
    "d(x_{i},x_{j}) \\approx d(f(x_{i}),f(x_{j}))\n",
    "$$\n",
    "\n",
    "- The idea is to use the provided train set to create features for each embedding and image in the test data \n",
    "by calculating - for each sample - the cosine similarity between it and all the available samples in the training data.\n",
    "\n",
    "- Since the cosine similarity is preserved the corresponding test embeddings and images should end up with similar features.\n",
    "\n",
    "- To find the embedding of a given image $x$ we search for embedding $y$ with the highest similarity,the index of that embedding is : \n",
    "\n",
    "$$\n",
    "\\argmax_{y \\in D'} d(x,y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the cost matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(x : Tensor, y : Tensor) -> Tensor:\n",
    "    \n",
    "    x = x.view(x.size(0), -1)\n",
    "    y = y.view(y.size(0), -1)\n",
    "\n",
    "    x = F.normalize(x, p=2, dim=1)\n",
    "    y = F.normalize(y, p=2, dim=1)\n",
    "\n",
    "    return x @ y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 128])\n"
     ]
    }
   ],
   "source": [
    "x_sim = cos_sim(dtest, dtrain[train_labels.values.flatten()])\n",
    "print(x_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 128])\n"
     ]
    }
   ],
   "source": [
    "emb_sim = cos_sim(test_embeddings_tensor, train_embeddings_tensor)\n",
    "print(emb_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "sim = cos_sim(emb_sim, x_sim)\n",
    "print(sim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8362"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sim.argmax(dim=1)\n",
    "np.mean(predictions.numpy() == test_labels.values.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimize using assignment algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix = 1 - sim.numpy()\n",
    "row_ind, col_ind = linear_sum_assignment(cost_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(col_ind == test_labels.values.flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
